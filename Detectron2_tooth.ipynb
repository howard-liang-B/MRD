{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8l2Kg-mZ1Pb"
   },
   "source": [
    "# Train custom instance segmentation model using Detectron2 - on your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTO_K23JaAxg"
   },
   "source": [
    "Create your own dataset by annotating for object detection using your favorite annotation software that can export annotations as COCO JSON format. I have used https://www.makesense.ai/ for my tutorial. I used the polygon tool to annotate objects and exported annotations as, \"Single file in COCO JSON format\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewiM3shDabuw"
   },
   "source": [
    "## Install Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 132509,
     "status": "ok",
     "timestamp": 1748194200682,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "FsePPpwZSmqt",
    "outputId": "e6075090-cd37-4d4c-9582-97e12de74648"
   },
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "!pip install onnx\n",
    "\n",
    "'''------------------------------------------------------------------------------------'''\n",
    "# Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3280,
     "status": "ok",
     "timestamp": 1748194203974,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "Ymh1ZusxDdST",
    "outputId": "c6950b18-eb5e-4d69-8c93-563fdd402222"
   },
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 101260,
     "status": "ok",
     "timestamp": 1748194305260,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "w3RUzXAwDpmi"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# Use for export onnx\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.export import TracingAdapter\n",
    "from detectron2.data import build_detection_test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2yUBzSPFPAS"
   },
   "source": [
    "# Train on a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3smwMVLOrEGK"
   },
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FikRIR7S1uEO"
   },
   "source": [
    "Import the necessary function to register datasets in the COCO format. Let us register both the training and validation datasets. Please note that we are working with training (and validation) data that is is the coco format where we have a single JSON file that describes all the annotations from all training images. <p>\n",
    "Here, we are naming our training data as 'my_dataset_train' and the validation data as 'my_dataset_val'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1719,
     "status": "ok",
     "timestamp": 1748194307021,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "iQskUfB1P9Ez",
    "outputId": "30f3a7c0-cd97-44ae-cce3-990a60c3cc25"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "class_name = 'tooth'\n",
    "dataset_dir = f'{class_name}_dataset_3'\n",
    "model_name = 'mask_rcnn_R_50_FPN_3x'\n",
    "# model_name = 'mask_rcnn_R_101_FPN_3x'\n",
    "# model_name = 'mask_rcnn_R_50_C4_1x'\n",
    "# model_name = 'mask_rcnn_R_50_C4_3x'\n",
    "\n",
    "print(\"train images count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + f\"/train_image\")))\n",
    "print(\"valid images count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + f\"/valid_image\")))\n",
    "print(\"valid masks count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + f\"/valid_mask\")))\n",
    "\n",
    "# def clear_directory(dir_path):\n",
    "#     for filename in os.listdir(dir_path):\n",
    "#         file_path = os.path.join(dir_path, filename)\n",
    "#         try:\n",
    "#             if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "#                 os.unlink(file_path)  # 刪除檔案或符號連結\n",
    "#             elif os.path.isdir(file_path):\n",
    "#                 shutil.rmtree(file_path)  # 刪除資料夾\n",
    "#         except Exception as e:\n",
    "#             print(f'無法刪除 {file_path}。原因: {e}')\n",
    "# clear_directory(\"AHE_dataset/\" + dataset_dir + f\"/valid_results_instance({model_name})\")\n",
    "# os.makedirs(\"AHE_dataset/\" + dataset_dir + f\"/valid_results_instance({model_name})\", exist_ok=True)\n",
    "# print(\"valid instance masks count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + f\"/valid_results_instance({model_name})\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1748194307065,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "ssw3M-5HFQ3a"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, f\"./detectron2/AHE_dataset/{dataset_dir}/coco/{class_name}_annotations_aug.json\", f\"./detectron2/AHE_dataset/{dataset_dir}/train_image\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, f\"./detectron2/AHE_dataset/{dataset_dir}/coco/{class_name}_annotations.json\", f\"./detectron2/AHE_dataset/{dataset_dir}/valid_image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2v-UIOU2TOF"
   },
   "source": [
    "Let us extract the metadata and dataset dictionaries for both training and validation datasets. These can be used later for other purposes, like **visualization**, **model training**, **evaluation**, etc. We will see a visualization example right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1748194308301,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "tYOyee79IxHz",
    "outputId": "8b1a9516-1769-4ff9-8862-5782e9eb2fa9"
   },
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1748194308982,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "RlG0ZUAwK4cU",
    "outputId": "0f7ddc62-098c-420d-d1eb-94ebdfe5bd43"
   },
   "outputs": [],
   "source": [
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
    "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1748194312125,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "nl5b9KPyLRfc",
    "outputId": "a2df3736-7160-407d-cd62-c2171ae26ec2"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Visualize some random samples\n",
    "for d in random.sample(train_dataset_dicts, 2):\n",
    "    print(\"影像檔名：\", d[\"file_name\"])  # 印出影像名稱\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gQNZNnWLpnc"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyoliSNg2upa"
   },
   "source": [
    "Now we are ready to train a Mask R-CNN model using the Detectron2 library. We start by setting up a configuration file (.cfg) for the model. The configuration file contains many details including the output directory path, training dataset information, pre-trained weights, base learning rate, maximum number of iterations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3705,
     "status": "ok",
     "timestamp": 1747978361449,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "-iPBoV69LrOE",
    "outputId": "eeb4deda-2c3b-4104-c3ad-a20710f62940"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = f\"./detectron2/AHE_dataset/{dataset_dir}/model\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(f\"COCO-InstanceSegmentation/{model_name}.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(f\"COCO-InstanceSegmentation/{model_name}.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.MAX_ITER = 1000    # 1000 iterations seems good enough for this dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # We have 4 classes.\n",
    "# NOTE: this config means the number of classes, without the background. Do not use num_classes+1 here.\n",
    "if LR == \"1\":\n",
    "  cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "elif LR == \"2\":\n",
    "  cfg.SOLVER.OPTIMIZER = \"Adam\"\n",
    "  cfg.SOLVER.BASE_LR = 0.0025\n",
    "  cfg.SOLVER.WARMUP_ITERS = 200\n",
    "  cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
    "  cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"  # 加這行指定 scheduler\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) #Create an instance of of DefaultTrainer with the given congiguration\n",
    "trainer.resume_or_load(resume=False) #Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrnDImFQ3XVH"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 370550,
     "status": "ok",
     "timestamp": 1747978732003,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "CNE3JZllGHB1",
    "outputId": "cc5892d0-24b6-4651-8cc1-c787fd69183a"
   },
   "outputs": [],
   "source": [
    "trainer.train() #Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1747978732106,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "EQlUEEKBXaH2",
    "outputId": "8dc72a74-bb6b-4ac7-e3e5-6f4cefe5b565"
   },
   "outputs": [],
   "source": [
    "os.makedirs((\"AHE_dataset/\" + dataset_dir + f\"/valid_results_instance({model_name})\"), exist_ok=True)\n",
    "print(\"images count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + \"/valid_results\")))\n",
    "print(\"masks count: \", len(os.listdir(\"AHE_dataset/\" + dataset_dir + f\"/valid_results_instance({model_name})\")))\n",
    "os.rename(f\"./detectron2/AHE_dataset/{dataset_dir}/model/metrics.json\", f\"./detectron2/AHE_dataset/{dataset_dir}/model/{class_name}_metrics({model_name}).json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41JtQgQvybb-"
   },
   "source": [
    "Save the config file, for potential future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI3zLAc3yeWq"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Save the configuration to a config.yaml file\n",
    "# Save the configuration to a config.yaml file\n",
    "config_yaml_path = f\"./detectron2/AHE_dataset/{dataset_dir}/model/config.yaml\"\n",
    "with open(config_yaml_path, 'w') as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgcPBalGMB4d"
   },
   "source": [
    "# Inference & evaluation using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1747978733776,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "iyyRL4soMDdE",
    "outputId": "e1b452c1-85f1-41f0-d0dc-865932698692"
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00pZTVD_WaRQ"
   },
   "source": [
    "Verify segmentation on random validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1747978734753,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "2z8JER1KM2Ul",
    "outputId": "fd7be1b1-49ac-48df-9ef8-c54e707acfca"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(val_dataset_dicts, 1):    #select number of images for display\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=val_metadata,\n",
    "                   scale=0.7,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F26poTkLPQzk"
   },
   "source": [
    "Check average precision and recall. (Need more validation data than just 2 images with handful of annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 28781,
     "status": "ok",
     "timestamp": 1747607831611,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "PQNSml38OuWV",
    "outputId": "be449f4f-51d9-4e3d-b11b-0f114e7d5a48"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=f\"./AHE_dataset/{dataset_dir}/output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95Ph5_JgXFJu"
   },
   "source": [
    "**Process multiple images in a directory and save the results in an output directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21194,
     "status": "ok",
     "timestamp": 1747607852823,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "VSycv0yeT7IM",
    "outputId": "79691a46-21b0-413b-d1a6-230684d3f7bb"
   },
   "outputs": [],
   "source": [
    "# Directory path to the input images folder\n",
    "input_images_directory = f\"./detectron2/AHE_dataset/{dataset_dir}/valid_image\"\n",
    "\n",
    "# Output directory where the segmented images will be saved\n",
    "output_directory = f\"./detectron2/AHE_dataset/{dataset_dir}/valid_results\"  # Replace this with the path to your desired output directory\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop over the images in the input folder\n",
    "for image_filename in os.listdir(input_images_directory):\n",
    "    print(\"image: \", image_filename)\n",
    "    image_path = os.path.join(input_images_directory, image_filename)\n",
    "\n",
    "    image_name, image_ext = os.path.splitext(image_path)\n",
    "    if image_ext != \".png\":\n",
    "      continue\n",
    "\n",
    "    new_im = cv2.imread(image_path)\n",
    "\n",
    "    # Perform prediction on the new image\n",
    "    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "    # We can use `Visualizer` to draw the predictions on the image.\n",
    "    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    # Create the output filename with _result extension\n",
    "    result_filename = os.path.splitext(image_filename)[0] + \"_result.png\"\n",
    "    output_path = os.path.join(output_directory, result_filename)\n",
    "\n",
    "    # Save the segmented image\n",
    "    print(\"output_path: \", output_path)\n",
    "    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n",
    "\n",
    "print(\"Segmentation of all images completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoouGMEDZr24"
   },
   "source": [
    "\n",
    "**Segment images and save object level information into a csv file.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7434,
     "status": "ok",
     "timestamp": 1747607860258,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "o_dnA1u6Zaz8",
    "outputId": "c69c1daa-417a-442b-8caf-de0f4d9bbcbf"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "\n",
    "# Assuming you have already defined the 'predictor' object and loaded the model.\n",
    "# Also, make sure 'metadata' is defined appropriately.\n",
    "\n",
    "# Directory path to the input images folder\n",
    "input_images_directory = f\"./detectron2/AHE_dataset/{dataset_dir}/valid_image\"\n",
    "\n",
    "# Output directory where the CSV file will be saved\n",
    "output_csv_path = f\"./detectron2/AHE_dataset/{dataset_dir}/valid_results/output_objects.csv\"  # Replace this with the path to your desired output CSV file\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row in the CSV file\n",
    "    csvwriter.writerow([\"File Name\", \"Class Name\", \"Object Number\", \"Area\", \"Centroid\", \"BoundingBox\"])  # Add more columns as needed for other properties\n",
    "\n",
    "    # Loop over the images in the input folder\n",
    "    for image_filename in os.listdir(input_images_directory):\n",
    "        image_path = os.path.join(input_images_directory, image_filename)\n",
    "\n",
    "        '''------------注意---------------'''\n",
    "        image_name, image_ext = os.path.splitext(image_path)\n",
    "        if image_ext != \".png\":\n",
    "          continue\n",
    "        '''------------注意---------------'''\n",
    "\n",
    "        new_im = cv2.imread(image_path)\n",
    "\n",
    "        # Perform prediction on the new image\n",
    "        outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "        # Convert the predicted mask to a binary mask\n",
    "        mask = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy().astype(bool)\n",
    "\n",
    "        # Get the predicted class labels\n",
    "        class_labels = outputs[\"instances\"].pred_classes.to(\"cpu\").numpy()\n",
    "\n",
    "        # Debugging: print class_labels and metadata.thing_classes\n",
    "        #print(\"Class Labels:\", class_labels)\n",
    "        #print(\"Thing Classes:\", train_metadata.thing_classes)\n",
    "\n",
    "        # Use skimage.measure.regionprops to calculate object parameters\n",
    "        labeled_mask = label(mask)\n",
    "        props = regionprops(labeled_mask)\n",
    "\n",
    "        # Write the object-level information to the CSV file\n",
    "        for i, prop in enumerate(props):\n",
    "            object_number = i + 5  # Object number starts from 1\n",
    "            area = prop.area\n",
    "            centroid = prop.centroid\n",
    "            bounding_box = prop.bbox\n",
    "\n",
    "            # Check if the corresponding class label exists\n",
    "            if i < len(class_labels):\n",
    "                class_label = class_labels[i]\n",
    "                class_name = train_metadata.thing_classes[class_label]\n",
    "            else:\n",
    "                # If class label is not available (should not happen), use 'Unknown' as class name\n",
    "                class_name = 'Unknown'\n",
    "\n",
    "            # Write the object-level information to the CSV file\n",
    "            csvwriter.writerow([image_filename, class_name, object_number, area, centroid, bounding_box])  # Add more columns as needed for other properties\n",
    "\n",
    "print(\"Object-level information saved to CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3SJXvy8idl6"
   },
   "source": [
    "**Saving binary (actually multinary) images for each class for further processing.** Here, for each input image we will save n images corresponding to the number of classes. In our example, we will save 4 images for each image corresponding to the 4 classes. Each of these images will contain objects numbered 1, 2, 3, etc. - basically instance segmentation like images. These images can be used for further downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5651,
     "status": "ok",
     "timestamp": 1747607865908,
     "user": {
      "displayName": "how o o",
      "userId": "04370989348997419217"
     },
     "user_tz": -480
    },
    "id": "aEayWBdnnku6",
    "outputId": "0632646f-d220-4a3b-b541-838def967a50"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "# Directory path to the input images folder\n",
    "input_images_directory = f\"./detectron2/AHE_dataset/{dataset_dir}/valid_image\"\n",
    "\n",
    "# Output directory where the segmented images will be saved\n",
    "output_directory = f\"./detectron2/AHE_dataset/{dataset_dir}\" + f\"/valid_results_instance({model_name})\"  # Replace this with the path to your desired output directory\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Loop over the images in the input folder\n",
    "for image_filename in os.listdir(input_images_directory):\n",
    "    image_path = os.path.join(input_images_directory, image_filename)\n",
    "\n",
    "    '''------------注意---------------'''\n",
    "    image_name, image_ext = os.path.splitext(image_path)\n",
    "    if image_ext != \".png\":\n",
    "        continue\n",
    "    '''------------注意---------------'''\n",
    "\n",
    "    new_im = cv2.imread(image_path)\n",
    "\n",
    "    # Perform prediction on the new image\n",
    "    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "\n",
    "    # Create a dictionary to store the mask for each class with unique integer labels\n",
    "    class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.uint8, device=torch.device(\"cuda:0\"))\n",
    "                   for class_name in train_metadata.thing_classes}\n",
    "\n",
    "    # Assign a unique integer label to each object in the mask\n",
    "    for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n",
    "        class_name = train_metadata.thing_classes[pred_class]\n",
    "        class_masks[class_name] = torch.where(outputs[\"instances\"].pred_masks[i].to(device=torch.device(\"cuda:0\")),\n",
    "                                              i + 50,\n",
    "                                              class_masks[class_name])\n",
    "\n",
    "    # Save the masks for each class with unique integer labels\n",
    "    for class_name, class_mask in class_masks.items():\n",
    "        # Convert the tensor to a NumPy array and then to a regular (CPU) array\n",
    "        class_mask_np = class_mask.cpu().numpy()\n",
    "\n",
    "        # Create the output filename with _class_name_result.png extension\n",
    "        class_filename = os.path.splitext(image_filename)[0] + f\"_{class_name}_result.png\"\n",
    "        class_output_path = os.path.join(output_directory, class_filename)\n",
    "\n",
    "        # Save the image with unique integer labels\n",
    "        cv2.imwrite(class_output_path, class_mask_np.astype(np.uint8))\n",
    "\n",
    "print(\"Segmentation of all images completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cMQtGzZDam1Y",
    "l8oBbRc7Xksw"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
