{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcpix2ZouDeW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class_name = \"bone\"\n",
        "dataset_dir = f\"{class_name}_dataset_3\"\n",
        "mask_gt_dir = f\"valid_mask\"\n",
        "\n",
        "model = \"mask_rcnn_R_50_FPN_3x\"\n",
        "# model = \"mask_rcnn_R_101_FPN_3x\"\n",
        "# model = \"mask_rcnn_R_50_C4_1x\"\n",
        "# model = \"mask_rcnn_R_50_C4_3x\"\n",
        "# model = \"segformer\"\n",
        "# model = \"DeepLab(MobileNetv3)\"\n",
        "mask_pred_dir = f\"valid_results_instance({model})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdmwSK6KVuWk"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir(f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_gt_dir}\")))\n",
        "print(len(os.listdir(f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_pred_dir}\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NplTKi5V6FG"
      },
      "source": [
        "## 刪除不要的 mask 類別 ，記得要改路徑跟要保留的類別"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_F_ZB6gIV8_9"
      },
      "outputs": [],
      "source": [
        "mask_dir = f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_pred_dir}\" # !!!!!!!!!!!\n",
        "\n",
        "remove_count = 0\n",
        "for name in os.listdir(mask_dir):\n",
        "    mask_path = os.path.join(mask_dir, name)\n",
        "    mask = cv2.imread(mask_path)\n",
        "    split_name = name.split(\"_\")\n",
        "\n",
        "    if class_name not in split_name or mask.shape != (640, 640, 3):\n",
        "        # os.remove(mask_path)\n",
        "        print(\"remove : \", mask_path)\n",
        "        remove_count += 1\n",
        "\n",
        "print(\"remove count: \", remove_count)\n",
        "print(len(os.listdir(mask_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9QszO0VJEgf"
      },
      "source": [
        "## 更改檔名"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YlVVeDXwtoi4"
      },
      "outputs": [],
      "source": [
        "image_dir = f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_pred_dir}\"\n",
        "\n",
        "for name in os.listdir(image_dir):\n",
        "    temp_list = name.split(\"_\")\n",
        "    old_path = os.path.join(image_dir, name)\n",
        "    name = name.replace(\"_result\", \"\")\n",
        "    name = name.replace(f\"_{class_name}\", \"\")\n",
        "    new_path = os.path.join(image_dir, name)\n",
        "    new_path = new_path.replace(\".png\", \".png\")\n",
        "\n",
        "    # os.rename(old_path, new_path)\n",
        "    print(old_path)\n",
        "    print(new_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atze4JHPrO-a"
      },
      "outputs": [],
      "source": [
        "annotation_mask_dir = f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_gt_dir}\"\n",
        "prediction_mask_dir = f\"./detectron2/AHE_dataset/{dataset_dir}/{mask_pred_dir}\"\n",
        "# output_PV_mask_dir = \"./detectron2/AHE_dataset/bone_dataset_2/PA_mask\"\n",
        "# os.makedirs(output_PV_mask_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlbQA4C2o2H8"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir(annotation_mask_dir)))\n",
        "print(len(os.listdir(prediction_mask_dir)))\n",
        "# for mask_name in os.listdir(annotation_mask_dir):\n",
        "#   if mask_name not in os.listdir(prediction_mask_dir):\n",
        "#     print(mask_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijcwURWCJvws"
      },
      "source": [
        "## 計算每張照片的DSC、跟全部的DSC平均"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-9aA82stfrk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def dice_coefficient(true_mask, pred_mask):\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2.0 * np.sum(intersection) / (np.sum(true_mask) + np.sum(pred_mask))\n",
        "\n",
        "def jaccard_index(true_mask, pred_mask):\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    union = np.logical_or(true_mask, pred_mask)\n",
        "    return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def mask_iou(true_mask, pred_mask):\n",
        "    intersection = np.logical_and(true_mask, pred_mask).sum()\n",
        "    union = np.logical_or(true_mask, pred_mask).sum()\n",
        "    return 1.0 if union == 0 else intersection / union\n",
        "\n",
        "# ---- Per-class Metrics ----\n",
        "def per_class_pixel_accuracy(true_mask, pred_mask, num_classes):\n",
        "    acc_list = []\n",
        "    for cls in range(num_classes):\n",
        "        cls_true = (true_mask == cls)\n",
        "        cls_pred = (pred_mask == cls)\n",
        "        correct = np.sum(cls_true & cls_pred)\n",
        "        total = np.sum(cls_true)\n",
        "        acc = correct / total if total > 0 else np.nan\n",
        "        acc_list.append(acc)\n",
        "    return acc_list\n",
        "\n",
        "def per_class_precision(true_mask, pred_mask, num_classes):\n",
        "    precision_list = []\n",
        "    for cls in range(num_classes):\n",
        "        cls_true = (true_mask == cls)\n",
        "        cls_pred = (pred_mask == cls)\n",
        "        tp = np.sum(cls_true & cls_pred)\n",
        "        fp = np.sum(~cls_true & cls_pred)\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
        "        precision_list.append(precision)\n",
        "    return precision_list\n",
        "\n",
        "def per_class_recall(true_mask, pred_mask, num_classes):\n",
        "    recall_list = []\n",
        "    for cls in range(num_classes):\n",
        "        cls_true = (true_mask == cls)\n",
        "        cls_pred = (pred_mask == cls)\n",
        "        tp = np.sum(cls_true & cls_pred)\n",
        "        fn = np.sum(cls_true & ~cls_pred)\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
        "        recall_list.append(recall)\n",
        "    return recall_list\n",
        "\n",
        "'''----------------------------------------------------------------------------------'''\n",
        "# 創建 DataFrame\n",
        "results = pd.DataFrame()\n",
        "\n",
        "for mask_name in os.listdir(annotation_mask_dir):\n",
        "\n",
        "    if mask_name not in os.listdir(prediction_mask_dir):\n",
        "        print(mask_name, \" not in prediction dir\")\n",
        "        continue\n",
        "\n",
        "    annotation_image = cv2.imread((annotation_mask_dir + \"/\" + mask_name), cv2.IMREAD_GRAYSCALE)\n",
        "    prediction_image = cv2.imread((prediction_mask_dir + \"/\" + mask_name), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 調整預測遮罩大小\n",
        "    height, width = annotation_image.shape\n",
        "    prediction_image = cv2.resize(prediction_image, (width, height), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    num_classes = int(max(annotation_image.max(), prediction_image.max()) + 1)\n",
        "\n",
        "    # DSC、Jaccard、IoU (針對整體非背景區域計算)\n",
        "    dsc = round(dice_coefficient(annotation_image > 0, prediction_image > 0), 4)\n",
        "    jaccard = round(jaccard_index(annotation_image > 0, prediction_image > 0), 4)\n",
        "    iou = round(mask_iou(annotation_image > 0, prediction_image > 0), 4)\n",
        "\n",
        "    # Per-class metrics\n",
        "    acc_list = per_class_pixel_accuracy(annotation_image, prediction_image, num_classes)\n",
        "    prec_list = per_class_precision(annotation_image, prediction_image, num_classes)\n",
        "    recall_list = per_class_recall(annotation_image, prediction_image, num_classes)\n",
        "\n",
        "    row_data = {\n",
        "        'Image Name': mask_name,\n",
        "        'DSC': dsc,\n",
        "        'Jaccard Index': jaccard,\n",
        "        'IoU': iou\n",
        "    }\n",
        "\n",
        "    # 動態加上 per-class 欄位\n",
        "    for cls in range(num_classes):\n",
        "        row_data[f'Acc_Class{cls}'] = round(acc_list[cls], 4) if not np.isnan(acc_list[cls]) else None\n",
        "        row_data[f'Prec_Class{cls}'] = round(prec_list[cls], 4) if not np.isnan(prec_list[cls]) else None\n",
        "        row_data[f'Recall_Class{cls}'] = round(recall_list[cls], 4) if not np.isnan(recall_list[cls]) else None\n",
        "\n",
        "    results = pd.concat([results, pd.DataFrame([row_data])], ignore_index=True)\n",
        "\n",
        "'''----------------------------------------------------------------------------------'''\n",
        "# 計算平均\n",
        "average_row = {'Image Name': 'Average'}\n",
        "for col in results.columns:\n",
        "    if col != 'Image Name':\n",
        "        average_row[col] = round(results[col].mean(skipna=True), 4)\n",
        "\n",
        "results = pd.concat([results, pd.DataFrame([average_row])], ignore_index=True)\n",
        "\n",
        "'''----------------------------------------------------------------------------------'''\n",
        "# 輸出 Excel\n",
        "excel_file = f'./detectron2/AHE_dataset/{dataset_dir}/AHE_{class_name}_3_dsc({model})_perclass.xlsx'\n",
        "results.to_excel(excel_file, index=False)\n",
        "\n",
        "print(\"Results have been written to\", excel_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
